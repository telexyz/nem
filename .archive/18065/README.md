https://www.youtube.com/playlist?list=PLUl4u3cNGP63oMNUHXqIUcrkS2PivhN3k

https://math.mit.edu/~gs/learningfromdata

1. The Column Space of  Contains All Vectors 
2. Multiplying and Factoring Matrices 
3. Orthonormal Columns in  Give 
4. Eigenvalues and Eigenvectors
5. Positive Definite and Semidefinite Matrices
6. Singular Value Decomposition (SVD)
7. Eckart-Young: The Closest Rank  Matrix to 
8. Norms of Vectors and Matrices
9. Four Ways to Solve Least Squares Problems
10. Survey of Difficulties with 
11. Minimizing  Subject to 
12. Computing Eigenvalues and Singular Values
13. Randomized Matrix Multiplication
14. Low Rank Changes in  and Its Inverse
15. Matrices  Depending on , Derivative = 
16. Derivatives of Inverse and Singular Values
17. Rapidly Decreasing Singular Values
18. Counting Parameters in SVD, LU, QR, Saddle Points
19. Saddle Points Continued, Maxmin Principle
20. Definitions and Inequalities
21. Minimizing a Function Step by Step
22. Gradient Descent: Downhill to a Minimum
23. Accelerating Gradient Descent (Use Momentum)
24. Linear Programming and Two-Person Games
25. Stochastic Gradient Descent
26. Structure of Neural Nets for Deep Learning
27. Backpropagation: Find Partial Derivatives
28. Computing in Class [No video available]
29. Computing in Class (cont.) [No video available]
30. Completing a Rank-One Matrix, Circulants!
31. Eigenvectors of Circulant Matrices: Fourier Matrix
32. ImageNet is a Convolutional Neural Network (CNN), The Convolution Rule
33. Neural Nets and the Learning Function
34. Distance Matrices, Procrustes Problem
35. Finding Clusters in Graphs
36. Alan Edelman and Julia Language

## Assigments

https://ocw.mit.edu/courses/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/pages/assignments

## Final project

The project takes the place of what would have been the last three homework assignments for the course. You can work in groups of two or three. Pick one of the problems that we are learning about, and take it further—to numerical examples, to applications, to testing a solution algorithm, or certainly to computations (using any language). Submit a short proposal just before or just after Spring Break. The project is due at the end of the last class.

__Topic Ideas__:
- SVD Applications to PCA 
- Comparison of Algorithms
- Applications to Random Matrices
- Least Squares Comparisons of 4 Ways: Speed and Accuracy
- Comparison with Gradient Algorithms
- Sparse Solutions Using l_1 
- Basis Pursuit and Other l_1 Optimizations Matrix Completion
- Gradient Descent and Stochastic Gradient Descent
- Acceleration Methods
- Learning Weights in a Neural Net
- Many Many Parameters—which Solution is Found by Descent?
- Low Rank Approximations
- Basic Applications